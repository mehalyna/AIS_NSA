# Enhancing Negative Selection Algorithm with Mahalanobis Distance

## Overview

This repository contains code and documentation for a research project that enhances the classic Negative Selection Algorithm (NSA) by replacing Euclidean distance with Mahalanobis distance. The aim is to improve anomaly detection in high-dimensional, correlated network traffic data (e.g., UNSW-NB15).

Key contributions:
1. Demonstrate that Mahalanobis-based NSA (“Mahalanobis-NSA”) significantly outperforms Euclidean-NSA on the UNSW-NB15 dataset.
2. Provide a complete Python prototype for data preprocessing, detector generation, anomaly scoring, and evaluation.
3. Analyze computational requirements and discuss optimizations.

---

## Table of Contents

1. [Introduction](#introduction)  
2. [Literature Review](#literature-review)  
3. [Dataset: UNSW-NB15](#dataset-unsw-nb15)  
4. [Methodology](#methodology)  
   1. [Data Loading & Preprocessing](#data-loading--preprocessing)  
   2. [Covariance Estimation & Inversion](#covariance-estimation--inversion)  
   3. [Detector Generation via Negative Selection](#detector-generation-via-negative-selection)  
   4. [Anomaly Scoring & Threshold Selection](#anomaly-scoring--threshold-selection)  
5. [Implementation](#implementation)  
   1. [Dependencies](#dependencies)  
   2. [Data Preprocessing Code](#data-preprocessing-code)  
   3. [Mahalanobis Core & Detector Generation](#mahalanobis-core--detector-generation)  
   4. [Anomaly Scoring and Evaluation](#anomaly-scoring-and-evaluation)  
6. [Results](#results)  
   1. [Euclidean-NSA Baseline](#euclidean-nsa-baseline)  
   2. [Mahalanobis-NSA Performance](#mahalanobis-nsa-performance)  
   3. [ROC & Precision–Recall Curves](#roc--precision–recall-curves)  
7. [Discussion & Limitations](#discussion--limitations)  
8. [Future Work](#future-work)  
9. [References](#references)

---

## Introduction

Anomaly detection in network traffic is critical for cybersecurity. Traditional signature-based systems fail against zero-day exploits and novel attack patterns. Bio-inspired approaches—like Artificial Immune Systems (AIS) and specifically the Negative Selection Algorithm (NSA)—offer a way to detect previously unseen anomalies by mimicking the immune system’s self/non-self discrimination.

However, classic NSA typically uses Euclidean distance, which does not account for varying scales or correlations among features. This leads to poor separation in high-dimensional, anisotropic feature spaces. We propose replacing Euclidean distance with Mahalanobis distance, which scales feature differences by the inverse covariance of the “self” (normal) data, thereby forming ellipsoidal boundaries around normal samples.

---

## Literature Review

1. **Forrest et al. (1994).**  
   Introduced NSA by analogy to T-cell selection: random detectors are tested against “self” strings, and those that match are discarded. Remaining detectors flag unseen inputs as anomalies.  
   *Forrest S., Perelson A. S., Allen L., Cherukuri R. (1994). Self-nonself discrimination in a computer. IEEE Symposium on Research in Security and Privacy.*

2. **Aickelin & Dasgupta (2002).**  
   Comprehensive tutorial on AIS, covering negative selection, clonal selection, and immune network models in intrusion detection.  
   *Aickelin U., Dasgupta D. (2002). Artificial Immune Systems. In: U. Aickelin & D. Dasgupta (eds), Artificial Immune Systems (Chapter 13).*

3. **Aickelin, Kendall & Timmis (2004).**  
   Explored AIS as a computational intelligence framework, discussing scalability and adaptation to dynamic data.  
   *Aickelin U., Kendall G., Timmis J. (2004). Artificial Immune Systems: A New Computational Intelligence Approach. Springer-Verlag.*

4. **De Castro & von Zuben (2000).**  
   Presented the Clonal Selection Algorithm (CLONALG) with engineering applications, demonstrating how mutation and cloning can refine detector pools.  
   *De Castro L.N., von Zuben F.J. (2000). The Clonal Selection Algorithm with Engineering Applications. GECCO’00 Workshop Proceedings.*

---

## Dataset: UNSW-NB15

[UNSW-NB15](https://www.kaggle.com/datasets/mrwellsdavid/unsw-nb15/data) is a benchmark dataset generated by the Australian Centre for Cyber Security. It contains real modern normal and malicious network traffic, with numbered features including packet-level attributes, flow-level statistics, and content-level details. Key facts:

- **49 total features**; we select numeric columns (40 attributes) and fill missing values with zero.
- **82,332 total records**, of which ∼37,000 are normal (`label = 0`) and the rest represent various attack categories (`label = 1`).
- Provides a realistic testbed for intrusion detection research.

---

## Methodology

### Data Loading & Preprocessing

1. **Read CSV & Select Numeric Features:**  
   Only numeric columns are retained because Mahalanobis distance operates on real-valued vectors.  
2. **Fill Missing Values:**  
   All NaN entries replaced with 0 to avoid issues in covariance computation.  
3. **Split `self_samples` and Test Set:**  
   - `self_samples` = all samples with `label == 0` (normal traffic).  
   - `test_features` and `test_labels` = full dataset for later scoring and evaluation.

---

### Covariance Estimation & Inversion

1. **Compute Covariance Matrix \(\Sigma\):**  
   \[
     \Sigma = \text{np.cov}( \text{self_samples},\, \text{rowvar} = False ).
   \]
2. **Regularization (Ridge):**  
   \[
     \Sigma_{\text{reg}} = \Sigma + \varepsilon I,\quad \varepsilon = 10^{-6}.
   \]  
   Prevents singularity when features are highly correlated.
3. **Invert Covariance:**  
   \[
     \Sigma^{-1} = \bigl(\Sigma_{\text{reg}}\bigr)^{-1}.
   \]
4. **Mahalanobis Distance:**  
   \[
     \Delta^M(x, y) = \sqrt{(x - y)^\top \,\Sigma^{-1}\,(x - y)}.
   \]

---

### Detector Generation via Negative Selection

1. **Uniform Sampling of Candidates:**  
   Generate 300 random points \(c \in [0,1]^d\).
2. **Distance Check:**  
   For each \(c\), compute \(\Delta^M(c, s_i)\) for all \(s_i \in \text{self_samples}\).
3. **Threshold \(r = 2.5\):**  
   If \(\min_i \Delta^M(c, s_i) > r\), accept \(c\) as a detector; otherwise, reject.
4. **Repeat Until \(N_D\) Detectors Collected.**  
   Final output is a NumPy array `detectors` of shape \((N_D, d)\).

---

### Anomaly Scoring & Threshold Selection

1. **Anomaly Score:**  
   For each test sample \(x\), compute  
   \[
     \text{score}(x) = \min_{d_j \in \text{detectors}} \Delta^M(x, d_j).
   \]
2. **Binary Classification via Threshold \(\theta\):**  
   - If \(\text{score}(x) < \theta\), classify as anomaly (attack).  
   - Otherwise, classify as normal.
3. **Evaluation Metrics:**  
   - Compute **ROC Curve**: (FPR vs. TPR) for varying \(\theta\).  
   - Compute **Precision–Recall Curve** for varying \(\theta\).  
   - Calculate **Average Precision (AP)** and **ROC–AUC**.  
   - For each threshold \(\theta\), compute Precision, Recall, and **F₁ Score**:  
     \[
       F_1 = 2 \times \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}.
     \]
4. **Select \(\theta^*\) Maximizing F₁.**  

---

## Implementation

### Dependencies

```bash
pip install numpy pandas scipy scikit-learn matplotlib
